{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237e6acd",
   "metadata": {},
   "source": [
    "# LangChain Notebook (Part 3): Embeddings (in depth) — Types, Choices, and Code\n",
    "\n",
    "This notebook continues from:\n",
    "- Part 1: Readers + `Document` + Cleaning\n",
    "- Part 2: Chunking + Tokenization + Context Window\n",
    "\n",
    "Here we focus **only on embeddings**:\n",
    "- What embeddings are (math + intuition)\n",
    "- **Different types of embeddings** used in modern RAG/search\n",
    "- How to use embeddings in LangChain (runnable examples)\n",
    "- Similarity computation and debugging\n",
    "- **Embedding cache** (production must-have)\n",
    "\n",
    "> ✅ Runs even without API keys using `FakeEmbeddings`.\n",
    "> Optional cells show Hugging Face or OpenAI embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fed4b6",
   "metadata": {},
   "source": [
    "## 0) Install & Imports\n",
    "\n",
    "If you see import errors, run:\n",
    "```python\n",
    "%pip install -U langchain langchain-core langchain-community numpy\n",
    "# Optional for Hugging Face local models:\n",
    "%pip install -U sentence-transformers\n",
    "# Optional for OpenAI embeddings:\n",
    "%pip install -U langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9ddd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"Ready ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41999bb",
   "metadata": {},
   "source": [
    "## 1) What is an embedding?\n",
    "\n",
    "An **embedding** is a vector (list of numbers) that represents meaning.\n",
    "\n",
    "**In RAG**:\n",
    "1) Embed each chunk  \n",
    "2) Store vectors in a vector DB  \n",
    "3) Embed the query  \n",
    "4) Retrieve nearest vectors → relevant chunks\n",
    "\n",
    "### Similarity metric: cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3fc14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    b = np.asarray(b, dtype=np.float32)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "cosine_similarity([1, 0], [1, 0]), cosine_similarity([1, 0], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438ed03",
   "metadata": {},
   "source": [
    "## 2) Embedding types you should know (interview + design)\n",
    "\n",
    "### A) Dense embeddings (most common)\n",
    "- Dense vector (e.g., 384/768/1024 dims)\n",
    "- Best for semantic similarity\n",
    "- Examples: MiniLM, E5, BGE, OpenAI text-embedding\n",
    "\n",
    "### B) Sparse embeddings (lexical)\n",
    "- Mostly zeros (BM25/TF-IDF-like, or neural sparse like SPLADE)\n",
    "- Strong on exact keywords, IDs, numbers\n",
    "\n",
    "### C) Hybrid retrieval (dense + sparse)\n",
    "- Often best in enterprise search\n",
    "\n",
    "### D) Late interaction / multi-vector (e.g., ColBERT)\n",
    "- Multiple vectors per document (token-level)\n",
    "- Higher accuracy, higher compute\n",
    "\n",
    "### E) Instruction-tuned embeddings\n",
    "- Optimized for query↔passage matching (E5/BGE instruction variants)\n",
    "\n",
    "### F) Multilingual embeddings\n",
    "- Cross-language aligned vectors (English/Italian/Kannada, etc.)\n",
    "\n",
    "### G) Domain/code embeddings\n",
    "- For logs, incidents, code search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566cc2b",
   "metadata": {},
   "source": [
    "## 3) Sample `Document`s for experiments\n",
    "\n",
    "If you already have `cleaned_docs` or `token_chunks` from previous notebooks,\n",
    "you can swap `sample_docs` with them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0cdafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " [{'source': 'kb', 'id': 'd1'},\n",
       "  {'source': 'kb', 'id': 'd2'},\n",
       "  {'source': 'report', 'id': 'd3'},\n",
       "  {'source': 'kb', 'id': 'd4'}])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs: List[Document] = [\n",
    "    Document(page_content=\"How to reset password in the portal: go to Settings -> Security -> Reset Password.\", metadata={\"source\": \"kb\", \"id\": \"d1\"}),\n",
    "    Document(page_content=\"Contact support by emailing support@example.com or opening a ticket in the portal.\", metadata={\"source\": \"kb\", \"id\": \"d2\"}),\n",
    "    Document(page_content=\"Quarterly summary report: revenue increased and customer satisfaction improved.\", metadata={\"source\": \"report\", \"id\": \"d3\"}),\n",
    "    Document(page_content=\"This doc mentions account security, MFA, and password policies.\", metadata={\"source\": \"kb\", \"id\": \"d4\"}),\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    \"I forgot my password. How can I reset it?\",\n",
    "    \"How do I reach support?\",\n",
    "    \"Tell me about quarterly performance.\",\n",
    "]\n",
    "len(sample_docs), [d.metadata for d in sample_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65114f50",
   "metadata": {},
   "source": [
    "## 4) LangChain Embeddings interface + a runnable baseline (`FakeEmbeddings`)\n",
    "\n",
    "Embeddings typically support:\n",
    "- `embed_documents(list[str]) -> list[list[float]]`\n",
    "- `embed_query(str) -> list[float]`\n",
    "\n",
    "We start with `FakeEmbeddings` so everything runs without downloads/API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "\n",
    "emb = FakeEmbeddings(size=384)\n",
    "doc_vectors = emb.embed_documents([d.page_content for d in sample_docs])\n",
    "q_vec = emb.embed_query(queries[0])\n",
    "\n",
    "len(doc_vectors), len(doc_vectors[0]), len(q_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7502e9",
   "metadata": {},
   "source": [
    "## 5) Manual similarity search (top-k)\n",
    "\n",
    "Before vector DBs, do this to validate:\n",
    "- vector dims\n",
    "- similarity code\n",
    "- query/doc pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cbec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_similar(query: str, docs: List[Document], embedding, k: int = 3) -> List[Tuple[float, Document]]:\n",
    "    q = np.array(embedding.embed_query(query), dtype=np.float32)\n",
    "    dvecs = embedding.embed_documents([d.page_content for d in docs])\n",
    "    scored = []\n",
    "    for d, v in zip(docs, dvecs):\n",
    "        s = cosine_similarity(q, np.array(v, dtype=np.float32))\n",
    "        scored.append((s, d))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return scored[:k]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"\\nQUERY:\", q)\n",
    "    for score, doc in top_k_similar(q, sample_docs, emb, k=3):\n",
    "        print(f\"  score={score:.4f} id={doc.metadata['id']}  {doc.page_content[:70]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247c98e",
   "metadata": {},
   "source": [
    "## 6) Real dense embeddings (Hugging Face) — Optional\n",
    "\n",
    "If you want real semantic vectors locally, use `sentence-transformers`.\n",
    "\n",
    "Starter models:\n",
    "- `sentence-transformers/all-MiniLM-L6-v2` (fast, 384 dim)\n",
    "- `intfloat/e5-small-v2` (instruction tuned; use prefixes)\n",
    "- `BAAI/bge-small-en-v1.5` (popular for RAG)\n",
    "\n",
    "> First run downloads weights (internet needed on your machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1216afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_HF = False  # set True when ready\n",
    "\n",
    "if USE_HF:\n",
    "    # %pip install -U sentence-transformers\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "    hf_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    hf_emb = HuggingFaceEmbeddings(\n",
    "        model_name=hf_model_name,\n",
    "        encode_kwargs={\"normalize_embeddings\": True},\n",
    "    )\n",
    "\n",
    "    for q in queries:\n",
    "        print(\"\\nQUERY:\", q)\n",
    "        for score, doc in top_k_similar(q, sample_docs, hf_emb, k=3):\n",
    "            print(f\"  score={score:.4f} id={doc.metadata['id']}  {doc.page_content[:70]}...\")\n",
    "else:\n",
    "    print(\"HF embeddings not enabled. Set USE_HF=True to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80c6b1",
   "metadata": {},
   "source": [
    "## 7) OpenAI embeddings — Optional (API key required)\n",
    "\n",
    "If you want OpenAI embeddings:\n",
    "- Install `langchain-openai`\n",
    "- Set environment variable `OPENAI_API_KEY`\n",
    "- Use `OpenAIEmbeddings(model=\"text-embedding-3-small\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86962ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_OPENAI = False  # set True when ready\n",
    "\n",
    "if USE_OPENAI:\n",
    "    # %pip install -U langchain-openai\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    oai_emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    for q in queries:\n",
    "        print(\"\\nQUERY:\", q)\n",
    "        for score, doc in top_k_similar(q, sample_docs, oai_emb, k=3):\n",
    "            print(f\"  score={score:.4f} id={doc.metadata['id']}  {doc.page_content[:70]}...\")\n",
    "else:\n",
    "    print(\"OpenAI embeddings not enabled. Set USE_OPENAI=True to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f56bc2",
   "metadata": {},
   "source": [
    "## 8) Instruction-tuned embeddings (E5/BGE) — input formatting\n",
    "\n",
    "Many models work better when you format inputs:\n",
    "\n",
    "### E5 format\n",
    "- query: `query: ...`\n",
    "- passage: `passage: ...`\n",
    "\n",
    "Why it matters:\n",
    "- The model was trained on this exact pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_e5(query: str = None, passage: str = None) -> str:\n",
    "    if query is not None:\n",
    "        return f\"query: {query}\"\n",
    "    if passage is not None:\n",
    "        return f\"passage: {passage}\"\n",
    "    raise ValueError(\"Provide query or passage\")\n",
    "\n",
    "print(format_for_e5(query=\"reset password\"))\n",
    "print(format_for_e5(passage=\"To reset password, go to Settings -> Security\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5fe58",
   "metadata": {},
   "source": [
    "## 9) Debugging embeddings (practical checklist)\n",
    "\n",
    "When embeddings feel “bad”, check:\n",
    "1) Cleaning quality (noise hurts embeddings)\n",
    "2) Chunk sizes (too big/too small)\n",
    "3) Normalization (`normalize_embeddings=True` for cosine)\n",
    "4) Query/passage prefixes (E5)\n",
    "5) Domain mismatch (use domain embeddings or hybrid retrieval)\n",
    "\n",
    "We’ll create a quick debug table: vector norm + preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62855596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_debug_table(docs: List[Document], embedding, max_preview: int = 60) -> List[Dict[str, Any]]:\n",
    "    vectors = embedding.embed_documents([d.page_content for d in docs])\n",
    "    table = []\n",
    "    for d, v in zip(docs, vectors):\n",
    "        v = np.array(v, dtype=np.float32)\n",
    "        table.append({\n",
    "            \"id\": d.metadata.get(\"id\"),\n",
    "            \"source\": d.metadata.get(\"source\"),\n",
    "            \"preview\": (d.page_content[:max_preview] + \"...\") if len(d.page_content) > max_preview else d.page_content,\n",
    "            \"dim\": int(v.shape[0]),\n",
    "            \"norm\": float(np.linalg.norm(v)),\n",
    "        })\n",
    "    return table\n",
    "\n",
    "embedding_debug_table(sample_docs, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f3d4e",
   "metadata": {},
   "source": [
    "## 10) Embedding cache (production must-have)\n",
    "\n",
    "Embedding the same chunks repeatedly is expensive.\n",
    "\n",
    "LangChain supports cache-backed embeddings:\n",
    "- First run → compute + store\n",
    "- Next run → load from cache\n",
    "\n",
    "This is great for:\n",
    "- repeated experiments\n",
    "- incremental indexing\n",
    "- speeding up development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81584b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "cache_dir = Path(\"emb_cache_store\")\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "store = LocalFileStore(str(cache_dir))\n",
    "\n",
    "cached_emb = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=emb,   # swap to hf_emb or oai_emb later\n",
    "    document_embedding_cache=store,\n",
    "    namespace=\"demo_v1\"\n",
    ")\n",
    "\n",
    "vecs_1 = cached_emb.embed_documents([d.page_content for d in sample_docs])\n",
    "vecs_2 = cached_emb.embed_documents([d.page_content for d in sample_docs])\n",
    "\n",
    "print(\"dim:\", len(vecs_1[0]))\n",
    "print(\"cache files:\", len(list(cache_dir.glob('*'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582c681",
   "metadata": {},
   "source": [
    "## 11) Choosing an embedding model (quick decision guide)\n",
    "\n",
    "- **Prototype fast**: MiniLM\n",
    "- **Best RAG retrieval**: E5 / BGE instruction variants\n",
    "- **Multilingual corpora**: multilingual-e5 / LaBSE-like\n",
    "- **ID/keyword heavy**: Hybrid retrieval (BM25 + dense)\n",
    "- **Highest precision**: late interaction (ColBERT) or rerankers\n",
    "\n",
    "Next notebook (recommended):\n",
    "✅ Vector DB insertion (Chroma/FAISS/Milvus) + Retrieval + Filters + MMR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
